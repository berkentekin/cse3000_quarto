---
title: "cse3000_quatro"
---

## Quarto

Install packages first

```{r}
if (!require("tidyverse")) {
  install.packages("tidyverse")
}

if (!require("stringdist")) {
  install.packages("stringdist")
}

if (!require("ggpmisc")) {
  install.packages("ggpmisc")
}

library("pcaPP")
library("gamlss")
library("gamlss.dist")
library("VGAM")

```

Helpful variables

```{r}
  snr_order <- c("n4", "n2", "0", "2", "4", "6", "8", "Q")

```

I first merge all data that I have, and create one DataFrame

```{r}
prep <- function(metadata_csv_loc, ...) {
  scores = list(...)
  stoi_scores_loc <- scores[["stoi_scores_loc"]]
  miknn_scores_loc <- scores[["miknn_scores_loc"]]
  siib_scores_loc <- scores[["siib_scores_loc"]]
  siib_scores_gaussian_loc <- scores[["siib_scores_gaussian_loc"]]
  siib_scores_gaussian_gapped_loc <- scores[["siib_scores_gaussian_gapped_loc"]]
  
  l1_data<- metadata_csv_loc |> read.csv(sep = ";") |> as_tibble()
  l1_stoi_scores <- stoi_scores_loc |> read.csv(sep=",") |> as_tibble()
  l1_miknn_scores <- miknn_scores_loc |> read.csv(sep=",") |> as_tibble()
  l1_siib_scores <- siib_scores_loc |> read.csv(sep=",") |> as_tibble()
  l1_siib_scores_gaussian <- siib_scores_gaussian_loc |> read.csv(sep=",") |> as_tibble()
    l1_siib_scores_gaussian_gapped <- siib_scores_gaussian_gapped_loc |> read.csv(sep=",") |> as_tibble()
  
  all_data <- l1_data |> 
    merge(l1_stoi_scores, by.x = c("audio", "snr"), by.y=c("filename", "snr"), all.x=TRUE) |>
     merge(l1_miknn_scores, by.x = c("audio", "snr"), by.y=c("CleanFile", "Degradation"), all.x=TRUE) |>
    merge(l1_siib_scores, by.x = c("audio", "snr"), by.y=c("filename", "snr"), all.x=TRUE) |>
    merge(l1_siib_scores_gaussian, by.x = c("audio", "snr"), by.y=c("filename", "snr"), all.x=TRUE) |>
    merge(l1_siib_scores_gaussian_gapped, by.x = c("audio", "snr"), by.y=c("filename", "snr"), all.x=TRUE) |>
    as_tibble()
  
  all_data <- rename(all_data, stoi_score=score)
  
  all_data <- all_data |> filter(trial>3)
  all_data <- replace_na(all_data, list(stoi_score=1))
  all_data <- mutate(.data=all_data, sim_wcr=autoscore/numwords, response_lc=tolower(response), target_lc=tolower(target), sim_editdist=stringsim(target_lc,response_lc))
  
}

all_data <- prep("data/l1res.csv",
                 stoi_scores_loc="data/stoi_scores.csv",
                 miknn_scores_loc="data/miknn_scores.csv",
                 siib_scores_loc="data/siib_scores.csv",
                 siib_scores_gaussian_loc="data/siib_scores_gaussian.csv",
                 siib_scores_gaussian_gapped_loc="data/siib_scores_gaussian_gapped.csv")

```

I assume a rater is "inaccurate" if they fail to score a clean file perfectly, and I discard all of their ratings.

```{r}

blacklist_wcr <- all_data |>
  select(id, snr, sim_wcr) |>
  filter(snr=="Q" & (sim_wcr < 1.0)) |>
  pull(id) |>
  unique()
  

blacklist_ed <- all_data |> 
  filter(snr=="Q" & (sim_editdist < 0.9)) |>
  select(id) |>
  unique() |>
  pull(id)

blacklist_all <- dplyr::union(blacklist_ed, blacklist_wcr)
```

### Some logistic functions

```{r math-formulas}


create_bins <- function(data, x) {
  binned_data <- data |> noq() |> mutate(
    bin = case_when(
      {{x}} == 0 ~ "0",
      {{x}} <= 0.2 ~ "0 < 0.2",
      {{x}} <= 0.4 ~ "0.2 - 0.4",
      {{x}} <= 0.6 ~ "0.4 - 0.6",
      {{x}} <= 0.8 ~ "0.6 - 0.8",
      {{x}} < 1 ~ "0.8 < 1",
      TRUE ~ "1"
    )
)
}

# If your formula is something like `wcr ~ stoi`:
# The predictor name is `stoi`, so the function signature should have `stoi` as the first argument.
logist_taal2010_stoi <- function(stoi, a, b, fac = 1) {
  fac / (1 + exp(a * stoi + b))
}

logist_taal2010_stoi_INVERSE <- function(stoi, a, b, fac = 1) {
  (log((fac / a) - 1) - b) / stoi
}

# If your formula is something like `wcr ~ nsec`:
# The predictor name is `nsec`.
logist_taal2010_nsec <- function(nsec, a, b, c, fac = 1) {
  fac / (1 + (a * nsec + b)^c)
}

rmse <- function(data, formula, f, fit) {
  # 1. Extract the response (left side) and predictor(s) (right side) from the formula
  lhs <- all.vars(formula)[1]        # response variable name
  rhs <- all.vars(formula)[-1]       # predictor variable name(s), if multiple, keep them all
  
  # 2. Get the actual data vectors
  observed <- data[[lhs]]           # the response in the data
  predictors <- data[rhs]           # a data.frame of predictors if multiple
  
  # 3. Extract the fitted coefficients from the model
  coefs <- coef(fit)
  
  # 4. Construct a list of arguments to pass to f()
  #    - f() must take the predictor(s) as first argument(s), 
  #      then the coefficients. 
  #    - If your function takes multiple predictors, adapt accordingly.
  f_args <- c(as.list(predictors), as.list(coefs))
  
  # 5. Generate predictions
  predicted <- do.call(f, f_args)
  
  # 6. Compute and return RMSE
  sqrt(mean((observed - predicted)^2, na.rm = TRUE))
}
```

I define some operators in case it's useful

```{r}
`%sp%` <- function(df, spk) {
  filter(df, speaker == spk)
}

`%snr%` <- function(df, val) {
  filter(df, snr == val)
}
```

Functions for easily filtering data

```{r}
filter_data <- function(data, col, val, bl, ...) {
  
  ls = list(...)

  data <- data |> 
    subset(!(id %in% bl)) |>
    filter({{col}} %in% {{val}})
  data
}

apply_bl <- function(data, bl) {
  data <- data |> subset(!(id %in% bl))
}

noq <- function(data) {
  data %>% filter(snr != 'Q')
}
```

Finally I use the function

```{r}
filtered_data <- apply_bl(
  data=all_data, 
  bl=blacklist_wcr)


```

TBD

```{r}
prep_plot <- function(data, x, y) {
  ggplot(data=data, aes(x={{x}}, y={{y}}, color = factor(snr, levels =   snr_order)))
}

prep_stoi_miknn_plot <- function(data) {
    ggplot(data=data, aes(x=stoi_score, y=MIKNNScore2x, color = factor(snr, levels =   snr_order)))
}

prep_stoi_siib_plot <- function(data) {
    ggplot(data=data, aes(x=stoi_score, y=siib_score_gaussian, color = factor(snr, levels =   snr_order)))
}
```

```{r}
p <- prep_plot(noq(filtered_data), stoi_score, MIKNNScore2x)
p + geom_point() + labs(x="STOI Score", y="MIKNN Score", color="SNR") + geom_smooth(method = "lm", se = FALSE, formula = y ~ x, color = "red")

p <- prep_plot(noq(filtered_data), stoi_score, siib_score)
p + geom_point() + labs(x="STOI Score", y="SIIB Score", color="SNR") + geom_smooth(method = "lm", se = FALSE, formula = y ~ x, color = "red")

p <- prep_plot(noq(filtered_data), stoi_score, siib_score_gaussian)
p + geom_point() + labs(x="STOI Score", y="SIIB Score (Gaussian)", color="SNR") + geom_smooth(method = "lm", se = FALSE, formula = y ~ x, color = "red")

p_siibgaus_siib <- prep_plot(noq(filtered_data), siib_score_gaussian, siib_score)
p_siibgaus_siib + geom_point() + labs(x="SIIB Score (Gaussian)", y="SIIB Score", color="SNR") + geom_smooth(method = "lm", se = FALSE, formula = y ~ x, color = "red")

p <- prep_plot(noq(filtered_data), stoi_score, siib_score_gaussian_gapped)
p + geom_point() + labs(x="STOI Score", y="SIIB Score (Gaussian)", color="SNR") + geom_smooth(method = "lm", se = FALSE, formula = y ~ x, color = "red")

p_siibgaus_siib <- prep_plot(noq(filtered_data), siib_score_gaussian_gapped, siib_score)
p_siibgaus_siib + geom_point() + labs(x="SIIB Score (Gaussian)", y="SIIB Score", color="SNR") + geom_smooth(method = "lm", se = FALSE, formula = y ~ x, color = "red")


p <- prep_plot(noq(filtered_data), siib_score_gaussian, siib_score_gaussian_gapped)
p + geom_point() + labs(x="SIIB gaus", y="SIIB Score (Gaussian) gapped", color="SNR") + geom_smooth(method = "lm", se = FALSE, formula = y ~ x, color = "red")

kendall_stoi_miknn <- cor(noq(filtered_data)$stoi_score, noq(filtered_data)$MIKNNScore2x, method = "kendall")
kendall_stoi_miknn

kendall_stoi_siib <- cor(noq(filtered_data)$stoi_score, noq(filtered_data)$siib_score, method = "kendall")
kendall_stoi_siib

kendall_stoi_siibgauss <- cor(noq(filtered_data)$stoi_score, noq(filtered_data)$siib_score_gaussian, method = "kendall")
kendall_stoi_siibgauss
```

\

```{r}
fit <- lm(data=noq(filtered_data), formula=siib_score_gaussian_gapped ~ siib_score_gaussian
          )

c<-cor(x=noq(filtered_data)$siib_score_gaussian, y=noq(filtered_data)$siib_score_gaussian_gapped, method="kendall")
summary(c)
```

```{r}
f53 <- filtered_data %sp% 53
p <- prep_plot(filtered_data, stoi_score, sim_wcr)
p + geom_point() + labs(x="STOI Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(filtered_data, stoi_score, sim_editdist)
p + geom_point() + labs(x="STOI Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(filtered_data |> noq(), siib_score, sim_wcr)
p + geom_point() + labs(x="SIIB Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(filtered_data |> noq(), siib_score_gaussian, sim_wcr)
p + geom_point() + labs(x="SIIB Score (Gaussian)", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(filtered_data |> noq(), MIKNNScore2x, sim_wcr)
p + geom_point() + labs(x="MIKNN Score", y="Subjective Score (WCR)", color="SNR")

#fit <- nls(sim_editdist ~ fun(stoi_score, a, b), start=list(a=-3,b=2), data=data)
#preds <- predict(fit)
#pearson_cor <- cor(data$stoi_score, data$sim_editdist, method = "pearson")
```

```{r}
all_wcrs <- all_data |> select(sim_wcr) |> unique()
all_wcrs <- all_data |> group_by(sim_wcr) |> summarise(avg_stoi_score = mean(stoi_score))

p <- ggplot(all_wcrs, aes(avg_stoi_score, sim_wcr))
p + geom_point()

all_stoi <- all_data |> group_by(stoi_score) |> summarise(avg_wcr = mean(sim_wcr))

p <- ggplot(all_stoi, aes(stoi_score, avg_wcr))
p + geom_point()

sampled_all_data <- all_data |> sample_n(500)

ggplot(sampled_all_data, aes(x=stoi_score, y=sim_wcr)) + geom_point()

all_stoi_binned <- all_data %>%
  # Create 10 bins (breaks = 10) across the full range of stoi_score
  mutate(stoi_bin = cut(stoi_score, breaks = 20, include.lowest = TRUE)) %>%
  # Group by the bin instead of the raw stoi_score
  group_by(stoi_bin) %>%
  summarise(avg_wcr = mean(sim_wcr, na.rm = TRUE))

pasb <- ggplot(all_stoi_binned, aes(x = stoi_bin, y = avg_wcr))

pasb +  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate labels if needed


all_stoi_binned_filt <- filtered_data %>%
  # Create 10 bins (breaks = 10) across the full range of stoi_score
  mutate(stoi_bin = cut(stoi_score, breaks = 20, include.lowest = TRUE)) %>%
  # Group by the bin instead of the raw stoi_score
  group_by(stoi_bin) %>%
  summarise(avg_wcr = mean(sim_wcr, na.rm = TRUE))

pasbf <- ggplot(all_stoi_binned_filt, aes(x = stoi_bin, y = avg_wcr))


ggplot() +
  geom_point(
    data = all_stoi_binned, 
    aes(x = stoi_bin, y = avg_wcr),
    color = "blue"        # for example
  ) +
  geom_point(
    data = all_stoi_binned_filt, 
    aes(x = stoi_bin, y = avg_wcr),
    color = "red"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

```{r}
get_id_samples <- function(data, percent) {
  sampled_ids <- data %>%
    dplyr::pull(id) %>% 
    unique() %>% 
    sample(size = ceiling(length(.) * (percent / 100))) 
 
  data <- data %>% noq() %>% filter(id %in% sampled_ids)
  ## Take the minimum among SNRs
  mc <- data %>% group_by(snr) %>% count(snr) %>% pull(n) %>% min()

  ## Prune data until there are equal number of samples for each SNR
  data <- data %>% group_by(snr) %>% slice_sample(n = mc) %>% ungroup()
  data <- data %>% mutate(snr = factor(snr,snr_order)) %>% mutate(
    snr_num = as.numeric(gsub("^n", "-", as.character(snr)))
  )
}

sampled_data <- get_id_samples(all_data, 5)
best_fit <- nls(
  data = sampled_data,
  formula = sim_wcr ~ logist_taal2010_stoi(stoi_score, a, b),
  start = c(a=0, b=0)
)

stoi_grid <- tibble(
  #avg_stoi = seq(min(dlss$avg_stoi), max(dlss$avg_stoi), length.out = 200)
  stoi_score = seq(0,1,length.out=200)
)

stoi_grid <- stoi_grid %>%
  mutate(wcr_pred = predict(best_fit, newdata = .))

sampled_data <- sampled_data %>% mutate(snr_num = as.factor(snr_num))

ggplot(sampled_data, aes(x=stoi_score, y=sim_wcr, color=snr_num)) +
  geom_jitter(width = 0.03, height = 0.03, alpha = 0.7) +  # Add jitter
  geom_point() +
  geom_line(data = stoi_grid, aes(x=stoi_score, y=wcr_pred), color='blue')

summary(best_fit)
```

```{r}

library("pcaPP")
# Author: Berken Tekin, GPT-4o
std_errs <- list()  # Use a list to store standard errors for each iteration
t_vals <- list()    # Use a list to store t-values for each iteration
residual_stderrs <- list()
std_errs_avg <- list()  # Use a list to store standard errors for each iteration
t_vals_avg <- list()    # Use a list to store t-values for each iteration
residual_stderrs_avg <- list()
ktaus <- list()
ktaus_avg <- list()


for (x in 1:100) {
  sampled_data <- get_id_samples(all_data, x)
  sampled_data_avg <- sampled_data |> noq() |> group_by(snr) |> summarise(avg_stoi = mean(stoi_score, na.rm=TRUE), avg_wcr = mean(sim_wcr, na.rm=TRUE)) |> ungroup() |> mutate(snr = factor(snr,snr_order)) |>   mutate(
    snr_num = as.numeric(gsub("^n", "-", as.character(snr)))
  )
  # Try fitting the model and handle potential errors
  best_fit <- tryCatch(
    nls(
      data = sampled_data,
      formula = sim_wcr ~ logist_taal2010_stoi(stoi_score, a, b),
      start = c(a = 0, b = 0)
    ),
    error = function(e) {
      message("Error in iteration ", x, ": ", e$message)
      return(NULL)
    }
  )
  best_fit_avg <- tryCatch(
    nls(
      data = sampled_data_avg,
      formula = avg_wcr ~ logist_taal2010_stoi(avg_stoi,a,b),
      start = c(a = 0, b = 0)
    ),
    error = function(e) {
      message("Error in iteration ", x, ": ", e$message)
      return(NULL)
    }
  )
  
  if (!is.null(best_fit)) {
    # Extract detailed summary
    model_summary <- summary(best_fit)
    ktaus[[x]] <- cor.fk(y=sampled_data$sim_wcr, x=sampled_data$stoi_score)
    
    # Extract standard errors and t-values
    std_errors <- model_summary$parameters[, "Std. Error"]
    t_values <- model_summary$parameters[, "t value"]
    residual_stderr <- model_summary[["sigma"]]
    
    # Name the entries in the t_values for consistency
    names(t_values) <- names(std_errors) <- c("a", "b")
    names(residual_stderr) <- c("residual_stderr")
    
    # Convert to data frame and add ID column
    std_errs[[x]] <- data.frame(ID = x, t(std_errors))
    t_vals[[x]] <- data.frame(ID = x, t(t_values))
    residual_stderrs[[x]] <- data.frame(ID = x, t(residual_stderr))

  } else {
    # Store NA if the model failed
    std_errs[[x]] <- data.frame(ID = x, a = NA, b = NA)
    t_vals[[x]] <- data.frame(ID = x, a = NA, b = NA)
  }
  
  
  if (!is.null(best_fit_avg)) {
    # Extract detailed summary
    model_summary_avg <- summary(best_fit_avg)
    
    ktaus_avg[[x]] <- cor(y=sampled_data_avg$avg_wcr, x=sampled_data_avg$avg_stoi, method="kendall")
    # Extract standard errors and t-values
    std_errors_avg <- model_summary_avg$parameters[, "Std. Error"]
    t_values_avg <- model_summary_avg$parameters[, "t value"]
    residual_stderr_avg <- model_summary_avg[["sigma"]]
    
    # Name the entries in the t_values for consistency
    names(t_values_avg) <- names(std_errors_avg) <- c("a", "b")
    names(residual_stderr_avg) <- c("residual_stderr")
    
    # Convert to data frame and add ID column
    std_errs_avg[[x]] <- data.frame(ID = x, t(std_errors_avg))
    t_vals_avg[[x]] <- data.frame(ID = x, t(t_values_avg))
    residual_stderrs_avg[[x]] <- data.frame(ID = x, t(residual_stderr_avg))

  } else {
    # Store NA if the model failed
    std_errs_avg[[x]] <- data.frame(ID = x, a = NA, b = NA)
    t_vals_avg[[x]] <- data.frame(ID = x, a = NA, b = NA)
  }
}

# Convert lists to data frames
std_errs_df <- do.call(rbind, std_errs)
t_vals_df <- do.call(rbind, t_vals)
residual_stderrs_df <- do.call(rbind, residual_stderrs)

std_errs_avg_df <- do.call(rbind, std_errs_avg)
t_vals_avg_df <- do.call(rbind, t_vals_avg)
residual_stderrs_avg_df <- do.call(rbind, residual_stderrs_avg)

# Convert to tibble for easier handling
t_vals_tibble <- as_tibble(t_vals_df)
t_vals_avg_tibble <- as_tibble(t_vals_avg_df)
std_errs_tibble <- as_tibble(std_errs_df)
std_errs_avg_tibble <- as_tibble(std_errs_avg_df)
residual_stderrs_tibble <- as_tibble(residual_stderrs_df)
residual_stderrs_avg_tibble <- as_tibble(residual_stderrs_avg_df)
# Display results
print("Standard Errors across iterations:")
print(std_errs_df)

print("t-values across iterations:")
print(t_vals_tibble)

# Assuming your dataframe is named df
# Create the plot
ggplot(t_vals_tibble, aes(x = ID, y = a)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. t value for a",
    x = "Sample Rate (ID)",
    y = "t value for fitted param a",
  ) +
  theme_minimal()         # Use a clean theme

ggplot(t_vals_tibble, aes(x = ID, y = b)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. t value for b",
    x = "Sample Rate (ID)",
    y = "t value for fitted param b",
  ) +
  theme_minimal()         # Use a clean theme

# Create the plot
ggplot(std_errs_tibble, aes(x = ID, y = a)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. stderr for a",
    x = "Sample Rate (ID)",
    y = "stderr for fitted param a",
  ) +
  theme_minimal()         # Use a clean theme

ggplot(std_errs_tibble, aes(x = ID, y = b)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. stderr for b",
    x = "Sample Rate (ID)",
    y = "stderr for fitted param b",
  ) +
  theme_minimal()         # Use a clean theme

ggplot(residual_stderrs_tibble, aes(x = ID, y = residual_stderr)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. stderr for b",
    x = "Sample Rate (ID)",
    y = "Residual standard error",
  ) +
  theme_minimal()         # Use a clean theme


######### AVGS
ggplot(t_vals_avg_tibble, aes(x = ID, y = a)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. t value for a",
    x = "Sample Rate (ID)",
    y = "t value for fitted param a",
  ) +
  theme_minimal()         # Use a clean theme

ggplot(t_vals_avg_tibble, aes(x = ID, y = b)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. t value for b",
    x = "Sample Rate (ID)",
    y = "t value for fitted param b",
  ) +
  theme_minimal()         # Use a clean theme

# Create the plot
ggplot(std_errs_avg_tibble, aes(x = ID, y = a)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. stderr for a",
    x = "Sample Rate (ID)",
    y = "stderr for fitted param a",
  ) +
  theme_minimal()         # Use a clean theme

ggplot(std_errs_avg_tibble, aes(x = ID, y = b)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. stderr for b",
    x = "Sample Rate (ID)",
    y = "stderr for fitted param b",
  ) +
  theme_minimal()         # Use a clean 


ggplot(residual_stderrs_avg_tibble, aes(x = ID, y = residual_stderr)) +
  geom_line() +           # Line plot
  geom_point() +          # Add points for each ID
  labs(
    title = "Sample Rate vs. stderr for b",
    x = "Sample Rate (ID)",
    y = "Residual standard error",
  ) +
  theme_minimal()         # Use a clean theme



```

### Experiment 1

```{r exp-1}
# 1- sample 5% for each different SNR, preferably with same listeners (cluster?) 

# 1. Identify all unique listeners
unique_ids <- unique(all_data$id)

# 2. Randomly sample 5% of them
sampled_ids <- sample(unique_ids, size = ceiling(length(unique_ids) * 1))

# 3. Filter all_data to just those IDs
data_lis_slice <- all_data %>%
  filter(id %in% sampled_ids)

## Take the minimum among SNRs
mc <- data_lis_slice |> group_by(snr) |> count(snr) |> pull(n) |> min()

## Prune data until there are equal number of SNRs 
data_lis_slice <- data_lis_slice |> group_by(snr) |> slice_sample(n = mc) |> ungroup()

listeners <- data_lis_slice |> pull(id) |> unique() |> sort() |> print()
dlss <- data_lis_slice |> noq() |> group_by(snr, gender) |> summarise(first_stoi = first(stoi_score), avg_stoi = mean(stoi_score, na.rm=TRUE), avg_wcr = mean(sim_wcr, na.rm=TRUE), avg_miknn = mean(MIKNNScore2x), avg_siib = mean(siib_score),avg_siibgg = mean(siib_score_gaussian_gapped)) |> ungroup() |> mutate(snr = factor(snr,snr_order)) |>   mutate(
  
    snr_num = as.numeric(gsub("^n", "-", as.character(snr)))
  )


dlss |> ggplot(aes(x=snr_num, y=avg_wcr)) + geom_point()
dlss |> ggplot(aes(x=snr_num, y=avg_stoi)) + geom_point()
dlss |> ggplot(aes(x=snr_num, y=first_stoi)) + geom_point()
dlss |> ggplot(aes(x=snr_num, y=avg_siibgg)) + geom_point()
dlss |> ggplot(aes(x=snr_num, y=avg_siib)) + geom_point()
dlss |> ggplot(aes(x=snr_num, y=avg_miknn)) + geom_point()
dlss |> ggplot(aes(x=avg_stoi, y=avg_wcr)) + geom_point()

# 2- Fit curve

fit_stoi_wcr <- nls(
  formula = avg_wcr ~ logist_taal2010_stoi(avg_stoi, a, b),
  data = dlss,
  start = list(a=0.5, b=0)
)

fit_snr_stoi <- nls(
  formula = avg_stoi ~ logist_taal2010_stoi(snr_num, a, b),
  data = dlss,
  start = list(a=0.5, b=0)
)
# summary(fit_stoi_wcr)
summary(fit_snr_stoi)
# Generate a sequence of STOI values over the range:
stoi_grid <- tibble(
  #avg_stoi = seq(min(dlss$avg_stoi), max(dlss$avg_stoi), length.out = 200)
  avg_stoi = seq(0,1,length.out=200)
)

given_log_stoi <- stoi_grid |> mutate(avg_wcr_pred= logist_taal2010_stoi(avg_stoi, -13.1903, 6.51))
#given_log_stoi <- stoi_grid |> mutate(avg_wcr_pred= logist_taal2010_stoi(avg_stoi, -15.15, 10.83))
given_log_stoi100 <- stoi_grid |> mutate(avg_wcr_pred= logist_taal2010_stoi(avg_stoi, -15.15, 10.83, fac=100))

# Predict over that grid
stoi_grid <- stoi_grid %>%
  mutate(avg_wcr_pred = predict(fit_stoi_wcr, newdata = .))

ggplot(dlss, aes(x=avg_stoi, y=avg_wcr)) +
  geom_point() +
  geom_line(data=stoi_grid, aes(x=avg_stoi, y=avg_wcr_pred), color="green", linewidth=1)

dlss <- dlss |> mutate(avg_wcr_scaled = avg_wcr * 100)

ggplot(dlss, aes(x=avg_stoi, y=avg_wcr)) +
  geom_point() +
  geom_line(data=stoi_grid, aes(x=avg_stoi, y=avg_wcr_pred), color="green", linewidth=1) +
  geom_line(data=given_log_stoi, aes(x=avg_stoi,y=avg_wcr_pred), color="blue", linewidth=1)


rmse(dlss |> mutate(stoi=avg_stoi, wcr=avg_wcr), wcr ~ stoi, logist_taal2010_stoi, fit_stoi_wcr)


# 3- Obtain listener IDs

# 4- Create samples for each SNR with different listener IDs

# 5- Test curve
```

```{r}

tidier <- function(data) {
  data <- data %>% noq() %>% mutate(snr = factor(snr,snr_order)) %>% mutate(
    snr = as.numeric(gsub("^n", "-", as.character(snr))))
}

data <- all_data %>% tidier()

data_grouped_by_id <- data %>% 
  group_by(id, snr) %>% 
  summarise(avg_wcr = mean(sim_wcr), 
            avg_stoi_score = mean(stoi_score), 
            avg_miknn_score = mean(MIKNNScore2x),
            avg_siib_score = mean(siib_score),
            avg_siib_score_gaussian_gapped = mean(siib_score_gaussian_gapped),
            avg_editdist = mean(sim_editdist),
            .groups="drop") %>% 
  mutate(snr = as_factor(snr))

best_fit_lt2010 <- nls(
  formula = avg_wcr ~ logist_taal2010_stoi(avg_stoi_score, a, b),
  data = data_grouped_by_id,
  start = c(a=0,b=0)
)

stoi_grid <- tibble(
  #avg_stoi = seq(min(dlss$avg_stoi), max(dlss$avg_stoi), length.out = 200)
  avg_stoi_score = seq(0,1,length.out=200)
) %>% mutate(avg_wcr_pred = predict(best_fit_lt2010, newdata = .))

data_grouped_by_id <- data_grouped_by_id %>% mutate(id = as.factor(id))




ggplot(data=data_grouped_by_id %>% sample_n(10), mapping = aes(x = avg_stoi_score, y = avg_wcr, color = snr)) + geom_point() +geom_line(data=stoi_grid, aes(x=avg_stoi_score, y=avg_wcr_pred), color="blue", linewidth=1)
ggplot(data=data_grouped_by_id, mapping = aes(x = snr, y = avg_wcr, color = id, group=id)) + geom_point() + geom_line() + theme(legend.position = "none")
ggplot(data=data_grouped_by_id, mapping = aes(x = avg_miknn_score, y = avg_wcr, color = snr)) + geom_point()
ggplot(data=data_grouped_by_id, mapping = aes(x = avg_siib_score, y = avg_wcr, color = snr)) + geom_point()
ggplot(data=data_grouped_by_id, mapping = aes(x = avg_siib_score_gaussian_gapped, y = avg_wcr, color = snr)) + geom_point()

avg_wcr_bins <- create_bins(data_grouped_by_id, avg_wcr)
avg_stoi_bins <- create_bins(data_grouped_by_id, avg_stoi_score)

avg_wcr_bins %>% ggplot(aes(x = bin)) + geom_histogram(stat = "count")
avg_stoi_bins %>% ggplot(aes(x = bin)) + geom_histogram(stat = "count")



data %>% noq() %>% create_bins(sim_wcr) %>% ggplot(aes(x = bin)) + geom_histogram(stat = "count")
data %>% noq() %>% create_bins(stoi_score) %>% ggplot(aes(x = bin)) + geom_histogram(stat = "count")

data %snr% -4 %>% tidier() %>% ggplot(aes(x = sim_wcr)) + geom_histogram(bins=8)

```

```{r}

p <- prep_plot(f53, stoi_score, sim_wcr)
p + geom_point() + labs(x="STOI Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(f53, stoi_score, sim_editdist)
p + geom_point() + labs(x="STOI Score", y="Subjective Score (stringdist)", color="SNR")

p <- prep_plot(f53 |> noq(), siib_score, sim_wcr)
p + geom_point() + labs(x="SIIB Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(f53 |> noq(), siib_score_gaussian, sim_wcr)
p + geom_point() + labs(x="SIIB Score (Gaussian)", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(f53 |> noq(), MIKNNScore2x, sim_wcr)
p + geom_point() + labs(x="MIKNN Score", y="Subjective Score (WCR)", color="SNR")

#fit <- nls(sim_editdist ~ fun(stoi_score, a, b), start=list(a=-3,b=2), data=data)
#preds <- predict(fit)
#pearson_cor <- cor(data$stoi_score, data$sim_editdist, method = "pearson")
```

Plots per SNR

```{r}

for (snr in snr_order) {
  p <- prep_plot(filtered_data %snr% snr, stoi_score, sim_wcr)
  print(p + geom_point() + labs(x="STOI Score", y="Subjective Score (WCR)", color="SNR"))
}



#fit <- nls(sim_editdist ~ fun(stoi_score, a, b), start=list(a=-3,b=2), data=data)
#preds <- predict(fit)
#pearson_cor <- cor(data$stoi_score, data$sim_editdist, method = "pearson")
```

Experiment: discard last word for SNR, removes clipping effects

```{r}
data_no_lw <- all_data
data_no_lw$target <- all_data["target"] |> sapply(function(x){sub("\\s+\\S+$", "", x)})
data_no_lw$response <- all_data["response"] |> sapply(function(x){sub("\\s+\\S+$", "", x)})

class(data_no_lw)

data_no_lw <- mutate(.data=data_no_lw, response_lc=tolower(response), target_lc=tolower(target), sim_editdist=stringsim(target_lc,response_lc))


f53 <- data_no_lw %sp% 53
p <- prep_plot(data_no_lw, stoi_score, sim_wcr)
p + geom_point() + labs(x="STOI Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(data_no_lw, stoi_score, sim_editdist)
p + geom_point() + labs(x="STOI Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(data_no_lw |> noq(), siib_score, sim_wcr)
p + geom_point() + labs(x="SIIB Score", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(data_no_lw |> noq(), siib_score_gaussian, sim_wcr)
p + geom_point() + labs(x="SIIB Score (Gaussian)", y="Subjective Score (WCR)", color="SNR")

p <- prep_plot(data_no_lw |> noq(), MIKNNScore2x, sim_wcr)
p + geom_point() + labs(x="MIKNN Score", y="Subjective Score (WCR)", color="SNR")
```

```{r}

some_ids <- data_grouped_by_id %>% ungroup() %>%
  distinct(id) %>% 
  slice_sample(n=5)   # 1% of unique IDs

# 2. Filter the data to keep only the sampled IDs
data_1pct <- data_grouped_by_id %>%
  filter(id %in% some_ids$id)

# 3. Plot avg_wcr vs. snr for the sampled IDs
ggplot(data_1pct, aes(x = snr, y = avg_wcr, color = id, group = id)) +
  geom_point() +
  geom_line() +
  labs(title = "1% of IDs: avg_wcr vs. SNR",
       x = "SNR",
       y = "Average WCR") +
  theme_minimal()

# 3. Plot avg_wcr vs. snr for the sampled IDs
ggplot(data_1pct, aes(x = snr, y = avg_editdist, color = id, group = id)) +
  geom_point() +
  geom_line() +
  labs(title = "1% of IDs: avg_editdist vs. SNR",
       x = "SNR",
       y = "Average WCR") +
  theme_minimal()

```
